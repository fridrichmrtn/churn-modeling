{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "##\n",
    "### COMBINED NEURAL NETWORK\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer\n",
    "\n",
    "class MultiOutputTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, y):\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "        y_class, y_reg = y[:, 0].reshape(-1,1), y[:, 1].reshape(-1,1)\n",
    "\n",
    "        self.class_encoder_ = OneHotEncoder(sparse=False)\n",
    "        self.reg_transformer_ = PowerTransformer()\n",
    "        # Fit them to the input data\n",
    "        self.class_encoder_.fit(y_class)\n",
    "        self.reg_transformer_.fit(y_reg)\n",
    "        # Save the number of classes\n",
    "        self.n_classes_ = len(self.class_encoder_.categories_)\n",
    "        self.n_outputs_expected_ = 2\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            y = y.values\n",
    "        y_class, y_reg = y[:, 0].reshape(-1,1), y[:, 1].reshape(-1,1)\n",
    "        # Apply transformers to input array\n",
    "        y_class = self.class_encoder_.transform(y_class)\n",
    "        y_reg = self.reg_transformer_.transform(y_reg)\n",
    "        # Split the data into a list\n",
    "        return [y_class, y_reg]\n",
    "\n",
    "    def inverse_transform(self, y, return_proba=False):\n",
    "        y_pred_reg = y[1]\n",
    "        if return_proba:\n",
    "            return y[0]\n",
    "        else:\n",
    "            y_pred_class = np.zeros_like(y[0])\n",
    "            y_pred_class[np.arange(len(y[0])), np.argmax(y[0], axis=1)] = 1\n",
    "            y_pred_class = self.class_encoder_.inverse_transform(y_pred_class)\n",
    "        y_pred_reg = self.reg_transformer_.inverse_transform(y_pred_reg)\n",
    "        return np.column_stack([y_pred_class, y_pred_reg])\n",
    "\n",
    "    def get_metadata(self):\n",
    "        return {\n",
    "            \"n_classes_\": self.n_classes_,\n",
    "            \"n_outputs_expected_\": self.n_outputs_expected_,\n",
    "        }\n",
    "\n",
    "from scikeras.wrappers import BaseWrapper\n",
    "from tensorflow.keras.initializers import HeNormal, LecunNormal, HeNormal\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, concatenate, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "class CombiNet(BaseWrapper):\n",
    "\n",
    "    def __init__(self, activation = \"selu\",\n",
    "        se_layers=1, se_units=256,\n",
    "        re_layers=5, re_units=100,\n",
    "        ce_layers=5, ce_units=100, cc_units=75,\n",
    "        epochs=10, verbose=0,\n",
    "        optimizer=\"adam\", optimizer__clipvalue=1.0, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.activation = activation\n",
    "            self.se_layers = se_layers\n",
    "            self.se_units = se_units\n",
    "            self.re_layers = re_layers\n",
    "            self.re_units = re_units\n",
    "            self.ce_layers = ce_layers\n",
    "            self.ce_units = ce_units\n",
    "            self.cc_units = cc_units\n",
    "            self.epochs = epochs\n",
    "            self.verbose = verbose\n",
    "            self.__prediction_scope = {\"classification\":0,\"regression\":1,\"full\":range(2)}\n",
    "\n",
    "    def _get_weight_init(self):\n",
    "        if isinstance(self.activation, LeakyReLU):\n",
    "            \n",
    "            init = HeNormal()\n",
    "        elif self.activation in [\"selu\", \"elu\"]:\n",
    "            init = LecunNormal()\n",
    "        else:\n",
    "            init = HeNormal()  \n",
    "        return init\n",
    "\n",
    "    def _keras_build_fn(self, compile_kwargs):\n",
    "        weight_init = self._get_weight_init()\n",
    "\n",
    "        # shared extraction\n",
    "        inp = Input(shape=(self.n_features_in_))\n",
    "        fe = inp\n",
    "        for i in range(self.se_layers):\n",
    "            fe = Dense(self.se_units, self.activation,\n",
    "                kernel_initializer=weight_init)(fe)\n",
    "            fe = BatchNormalization()(fe)\n",
    "        # regression branch\n",
    "        re = fe\n",
    "        for i in range(self.re_layers):\n",
    "            re = Dense(self.re_units, self.activation,\n",
    "                kernel_initializer=weight_init)(re)\n",
    "            re = BatchNormalization()(re)\n",
    "        rr_head = Dense(1,\"linear\")(re)\n",
    "        # classification branch\n",
    "        ce = fe\n",
    "        for i in range(self.ce_layers):\n",
    "            ce = Dense(self.ce_units, self.activation,\n",
    "                kernel_initializer=weight_init)(ce)\n",
    "            ce = BatchNormalization()(ce)\n",
    "        cc = Dense(self.cc_units, self.activation,\n",
    "            kernel_initializer=weight_init)(concatenate([ce, re]))\n",
    "        cc = BatchNormalization()(cc)\n",
    "        cc_head = Dense(2, \"softmax\")(cc)\n",
    "\n",
    "        model = Model(inputs=inp, outputs=[cc_head, rr_head])\n",
    "        model.compile(loss=[\"categorical_crossentropy\",\"mse\"], loss_weights=[.5,.5],\n",
    "            optimizer=compile_kwargs[\"optimizer\"])\n",
    "        return model\n",
    "        \n",
    "    @property\n",
    "    def target_encoder(self):\n",
    "        return MultiOutputTransformer()\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        X = self.feature_encoder_.transform(X)\n",
    "        y_pred = self.model_.predict(X)\n",
    "        return self.target_encoder_.inverse_transform(y_pred, return_proba=True)\n",
    "\n",
    "    def predict(self, X, scope=\"classification\"):\n",
    "        X = self.feature_encoder_.transform(X)\n",
    "        y_pred = self.model_.predict(X)\n",
    "        y_pred = self.target_encoder_.inverse_transform(y_pred)\n",
    "        return y_pred[:,self.__prediction_scope[scope]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import  _SigmoidCalibration\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "class CombiNetCalibrationCV(BaseEstimator):\n",
    "    def __init__(self, base_estimator, method=\"isotonic\", cv=2):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.method = method\n",
    "        self.cv = cv\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        calibrated_pairs = []\n",
    "        base_estimator = clone(self.base_estimator)\n",
    "        scv = StratifiedKFold(n_splits=2)\n",
    "        for train_index, test_index in scv.split(X, y[:,0]):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # fit combinet\n",
    "            base_estimator.fit(X_train, y_train)\n",
    "            y_pred = base_estimator.predict_proba(X_test)\n",
    "        \n",
    "            # fit calibrator\n",
    "            if self.method==\"isotonic\":\n",
    "                calibrator = IsotonicRegression(y_min=0,y_max=1, out_of_bounds=\"clip\")\n",
    "                calibrator.fit(y_pred[:,1].T, y_test[:,0])\n",
    "            if self.method==\"sigmoid\":\n",
    "                calibrator = _SigmoidCalibration()\n",
    "                calibrator.fit(y_pred[:,1].T, y_test[:,0])\n",
    "            calibrated_pairs.append((base_estimator, calibrator))\n",
    "        self.calibrated_pairs = calibrated_pairs\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # calibrated positive class\n",
    "        calibrated_class = np.zeros(shape=(X.shape[0], len(self.calibrated_pairs)))\n",
    "        for i, calibrated_pair in enumerate(self.calibrated_pairs):\n",
    "            raw_prediction = calibrated_pair[0].predict_proba(X)[:,1]\n",
    "            calibrated_class[:,i] = calibrated_pair[1].predict(raw_prediction)\n",
    "        calibrated_class = np.mean(calibrated_class, axis=1)\n",
    "        return np.column_stack([1-calibrated_class, calibrated_class])\n",
    "\n",
    "    def predict_reg(self, X):\n",
    "        calibrated_reg = np.zeros(shape=(X.shape[0], len(self.calibrated_pairs)))\n",
    "        for i, calibrated_pair in enumerate(self.calibrated_pairs):\n",
    "            calibrated_reg[:,i] = calibrated_pair[0].predict(X, scope=\"regression\")\n",
    "        return np.mean(calibrated_reg, axis=1)\n",
    "    \n",
    "    def predict_full(self, X):\n",
    "        return np.column_stack([(self.predict_proba(X)[:,1]>0.5).astype(\"int\"),\n",
    "            self.predict_reg(X)])\n",
    "    \n",
    "    def predict(self, X, scope=\"classification\"):\n",
    "\n",
    "        if scope==\"classification\":\n",
    "           return (self.predict_proba(X)[:,1]>0.5).astype(\"int\")\n",
    "        if scope==\"regression\":\n",
    "            return self.predict_reg(X)\n",
    "        if scope==\"full\":\n",
    "            return self.predict_full(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data load\n",
    "data = pd.read_parquet(\"../data/customer_model/retailrocket/\")\n",
    "train = data[data.week_step>2]\n",
    "test = data[data.week_step==2]\n",
    "\n",
    "out_cols = [\"user_id\", \"target_event\", \"target_revenue\", \"week_step\",\n",
    "    \"target_cap\"]\n",
    "feat_cols = [c for c in train.columns if c not in set(out_cols)]\n",
    "target_cols = [\"target_event\", \"target_cap\"]\n",
    "\n",
    "X = train.loc[:,feat_cols].values\n",
    "y = train.loc[:,target_cols].values\n",
    "\n",
    "calibrated_pipe =  CombiNetCalibrationCV(CombiNet()).fit(X, y)\n",
    "calibrated_pipe.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0302efd4727f45c27e6e7330619db7bcf8ae8a56f076c44e120407f8390c5d65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
